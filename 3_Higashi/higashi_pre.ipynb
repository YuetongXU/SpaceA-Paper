{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- cluster size ~ data count (cluster num reads num contacts num)\n",
    "\n",
    "chr count pct < 5% 弃掉最少chr ~ data count \n",
    "\n",
    "cis pct > 10%  ~ data count\n",
    "\n",
    "近距离互作 pair > 1000 ~ data count\n",
    "\n",
    "弃掉trans? ~ data count\n",
    "\n",
    "去掉背景spot -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# encoding: utf-8\n",
    "import os\n",
    "import assembly\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "from concurrent import futures\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "import subprocess\n",
    "\n",
    "def spot_sprite_to_higashi_v2(spot_id:str,in_spot_sprite_dir:str,out_spot_higashi_dir:str,chroms:list,\n",
    "                            min_cluster_size:int,max_cluster_size:int,close_contact_distance:int,\n",
    "                            count_normalize:bool,out_start_pos:bool):\n",
    "    os.makedirs(out_spot_higashi_dir,exist_ok=True)\n",
    "    in_spot_sprite_f=os.path.join(in_spot_sprite_dir,spot_id)\n",
    "    out_spot_higashi_f=os.path.join(out_spot_higashi_dir,f'{spot_id}.contact.tsv')\n",
    "    out_spot_higashi_tmp_f=out_spot_higashi_f+'.tmp'\n",
    "\n",
    "    close_contact_num=0\n",
    "    with open(in_spot_sprite_f,'r') as f,open(out_spot_higashi_tmp_f ,'w') as out:\n",
    "        for line in f:\n",
    "            cluster_reads = set(line.rstrip().split()[1:])\n",
    "            cluster_size = len(cluster_reads)\n",
    "            if min_cluster_size <= cluster_size <= max_cluster_size:\n",
    "                cluster_chr_reads_dict={chr:[] for chr in chroms}\n",
    "                for read in cluster_reads:\n",
    "                    chr=read.split(']_')[1].split(':')[0]\n",
    "                    start,end=read.split(']_')[1].split(':')[1].split('-')\n",
    "                    cluster_chr_reads_dict[chr].append([start,end])\n",
    "\n",
    "                for chr,cluster_chr_cis_reads in cluster_chr_reads_dict.items():\n",
    "                    if len(cluster_chr_cis_reads) >=2:\n",
    "                        for cluster_chr_cis_2_reads_comb in list(combinations(cluster_chr_cis_reads,2)):\n",
    "                            pair1=cluster_chr_cis_2_reads_comb[0]\n",
    "                            pair1_start=int(pair1[0])\n",
    "                            pair1_end=int(pair1[1])\n",
    "                            assert pair1_end>=pair1_start\n",
    "                            pair2=cluster_chr_cis_2_reads_comb[1]\n",
    "                            pair2_start=int(pair2[0])\n",
    "                            pair2_end=int(pair2[1])\n",
    "                            assert pair2_end>=pair2_start\n",
    "\n",
    "                            if pair1_start <= pair2_start:\n",
    "                                pass\n",
    "                            else:\n",
    "                                pair1_start,pair1_end,pair2_start,pair2_end=pair2_start,pair2_end,pair1_start,pair1_end\n",
    "\n",
    "                            if count_normalize:\n",
    "                                count_normalize=1/(cluster_size-1)\n",
    "                            else:\n",
    "                                count_normalize=1\n",
    "\n",
    "                            if (pair2_end-pair1_start >= close_contact_distance) or (pair2_start-pair1_start >= close_contact_distance):\n",
    "                                if out_start_pos:\n",
    "                                #  chrom1 pos1_start/pos1_end chrom2 pos2_start/pos2_end count[default:1]\n",
    "                                    out.write('\\t'.join([chr,str(pair1_start),chr,str(pair2_start),str(count_normalize)])+'\\n')\n",
    "                                else:\n",
    "                                    out.write('\\t'.join([chr,str(pair1_end),chr,str(pair2_end),str(count_normalize)])+'\\n')\n",
    "                            else:\n",
    "                                close_contact_num+=1\n",
    "\n",
    "                    else:\n",
    "                        pass\n",
    "            else:\n",
    "                pass\n",
    "    subprocess.run(f\"sort -k1,1V -k2,2n -k3,3V -k4,4n {out_spot_higashi_tmp_f} |uniq > {out_spot_higashi_f}\", shell=True)\n",
    "    os.remove(out_spot_higashi_tmp_f)\n",
    "    subprocess.run(f\"gzip -f {out_spot_higashi_f}\", shell=True)\n",
    "\n",
    "    return close_contact_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_sprite_to_higashi(cpus:int,spot_infor_f:str,in_spot_sprite_dir:str,\n",
    "                            out_spot_higashi_dir:str,chroms:list,\n",
    "                            min_cluster_size:int,max_cluster_size:int,close_contact_distance:int,\n",
    "                            out_spot_infor_f:str,count_normalize:bool,out_start_pos:bool):\n",
    "    spot_infor=pd.read_csv(spot_infor_f)\n",
    "    spotid_list=spot_infor.spot_id.unique().tolist()\n",
    "\n",
    "    with futures.ProcessPoolExecutor(max_workers=cpus) as pool:\n",
    "        func = partial(spot_sprite_to_higashi_v2,in_spot_sprite_dir=in_spot_sprite_dir,\n",
    "                       out_spot_higashi_dir=out_spot_higashi_dir,chroms=chroms,\n",
    "                            min_cluster_size=min_cluster_size,max_cluster_size=max_cluster_size,\n",
    "                            close_contact_distance=close_contact_distance,\n",
    "                            count_normalize=count_normalize,out_start_pos=out_start_pos)\n",
    "        close_contact_nums = list(tqdm(pool.map(func, spotid_list), total=len(spotid_list)))\n",
    "        spot_infor['cis_close_contact_num']=close_contact_nums\n",
    "        spot_infor['cis_close_contact_ratio']=spot_infor['cis_close_contact_num']/spot_infor['spot_fcsizefchrrnpfCsofcis_cis_ct_num']\n",
    "        spot_infor.to_csv(out_spot_infor_f,index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "work_dir='/home/spaceA'\n",
    "species='mm10'\n",
    "min_cluster_size=2\n",
    "max_cluster_size=1000\n",
    "chr_lst=list(assembly.build(species, 1)._chromsizes.keys())\n",
    "cpus=40\n",
    "close_contact_distance=1_000 #ref microC\n",
    "count_normalize=True\n",
    "out_start_pos=True\n",
    "\n",
    "\n",
    "def main(sample_name):\n",
    "    print(f'\\nNow process:{sample_name}')\n",
    "    in_spot_sprite_dir=os.path.join(work_dir,f'SpatialSPRITE_res/Filter_Spot_v4_tmp/clusters_{sample_name}_single_filtered_new_v2')\n",
    "    out_spot_higashi_dir=os.path.join(work_dir,f'higashi_pre_v2/{sample_name}')\n",
    "    spot_infor_f=os.path.join('/home/spaceA/SpatialSPRITE_res/Filter_Spot_v4_tmp',\n",
    "                              f'{sample_name}_spot_infor_final_v2.csv')\n",
    "    out_spot_infor_f =os.path.join('/home/spaceA/higashi_v2',sample_name+'_spot_infor_final_filtercloseCT.csv')\n",
    "\n",
    "    spot_infor=pd.read_csv(spot_infor_f)\n",
    "    spotid_list=spot_infor.spot_id.unique().tolist()\n",
    "\n",
    "    if not os.path.exists(out_spot_infor_f):\n",
    "        sample_sprite_to_higashi(cpus=cpus,spot_infor_f=spot_infor_f,\n",
    "                                in_spot_sprite_dir=in_spot_sprite_dir,\n",
    "                                out_spot_higashi_dir=out_spot_higashi_dir,chroms=chr_lst,\n",
    "                                min_cluster_size=min_cluster_size,max_cluster_size=max_cluster_size,\n",
    "                                close_contact_distance=close_contact_distance,\n",
    "                                out_spot_infor_f=out_spot_infor_f,\n",
    "                                count_normalize=count_normalize,\n",
    "                                out_start_pos=out_start_pos)\n",
    "    \n",
    "    out_spot_higashi_filelst_f=os.path.join(work_dir,f'higashi_v2/{sample_name}/filelist.txt')\n",
    "    os.makedirs(os.path.join(work_dir,f'higashi_v2/{sample_name}'),exist_ok=True)\n",
    "\n",
    "    with open(out_spot_higashi_filelst_f,'w') as f:\n",
    "        for spot in spotid_list:\n",
    "            spot_f_path=os.path.join(out_spot_higashi_dir,f'{spot}.contact.tsv.gz')\n",
    "            f.write(f'{spot_f_path}\\n')\n",
    "    print(f'{sample_name} done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/spaceA/config_v2.yaml\", \"r\") as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "sampleid_list=config['spatial_infor'].keys()\n",
    "\n",
    "for sample in sampleid_list:\n",
    "    main(sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
