{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "import json\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams[\"pdf.fonttype\"] = 42\n",
    "mpl.rcParams[\"ps.fonttype\"] = 42\n",
    "import scanpy as sc\n",
    "import assembly\n",
    "import subprocess\n",
    "\n",
    "sc.settings.verbosity = 0  # verbosity: errors (0), warnings (1), info (2), hints (3)\n",
    "sc.set_figure_params(scanpy=True, dpi=100, dpi_save=300, facecolor='white', frameon=True, vector_friendly=True, \n",
    "                     fontsize=12,\n",
    "                    #  figsize=(4,4),\n",
    "                     color_map=None, format='png', transparent=False, ipython_format='png2x')\n",
    "sc.settings.n_jobs=1\n",
    "sc.settings.figdir = \"./\"\n",
    "\n",
    "sys.path.append('/home/GitHub/3Dgenome/Higashi-main')\n",
    "sys.path.append('/home/GitHub/3Dgenome/Fast-Higashi-main')\n",
    "from fasthigashi.FastHigashi_Wrapper import *\n",
    "from higashi.Higashi_wrapper import *\n",
    "\n",
    "species='mm10'\n",
    "chroms=list(assembly.build(species, 1)._chromsizes.keys())\n",
    "work_dir='/home/spaceA'\n",
    "cpu_num=60\n",
    "filter_spot=False\n",
    "umap_n_neighbors=20\n",
    "tolerance= 3e-4 # 2e-5 3e-4\n",
    "restore_order=False\n",
    "do_conv=True\n",
    "do_rwr=False\n",
    "embed_type='embed_l2_norm'\n",
    "batch_norm=False\n",
    "\n",
    "out_dir=os.path.join(work_dir,'higashi_v2','fasthigashi','intergrade_v2')\n",
    "os.makedirs(out_dir,exist_ok=True)\n",
    "os.chdir(out_dir)\n",
    "\n",
    "with open(\"/home/spaceA/config.yaml\", \"r\") as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "sampleid_list=config['spatial_infor'].keys()\n",
    "kept_samples= ['E11.5L1', 'E11.5L2', 'E12.5L5', 'E12.5L6', 'E13.5C1', \n",
    "                'E13.5C4', 'E13.5C6', 'E14.5F5', 'E14.5F6']\n",
    "len(kept_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E11.5L1',\n",
       " 'E11.5L2',\n",
       " 'E12.5L5',\n",
       " 'E12.5L6',\n",
       " 'E13.5C1',\n",
       " 'E13.5C4',\n",
       " 'E13.5C6',\n",
       " 'E14.5F5',\n",
       " 'E14.5F6']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kept_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. prepare the fasthigashi input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mk filelist & prepare spot contact files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_intergrade_fasthigashi_spot_dir=os.path.join(work_dir,'higashi_pre_v2/intergrade')\n",
    "os.makedirs(out_intergrade_fasthigashi_spot_dir,exist_ok=True)\n",
    "\n",
    "out_spot_higashi_filelst_f=os.path.join(out_dir,'filelist.txt')\n",
    "if not os.path.exists(out_spot_higashi_filelst_f):\n",
    "    with open(out_spot_higashi_filelst_f,'w') as f:\n",
    "        for sample_name in tqdm(kept_samples):\n",
    "            print(sample_name)\n",
    "            spot_infor_f=os.path.join(work_dir,'higashi_v2','fasthigashi',sample_name+'_fasthigashi_obs_new.csv')\n",
    "            spot_infor_tmp=pd.read_csv(spot_infor_f,index_col=0)\n",
    "            for spot in spot_infor_tmp.spot_id.tolist(): # 文件保持spot顺序\n",
    "                in_spot_higashi_dir=os.path.join(work_dir,f'higashi_pre_v2/{sample_name}')\n",
    "                spot_f_path=os.path.join(in_spot_higashi_dir,f'{spot}.contact.tsv.gz')\n",
    "                out_spot_lnk_path=os.path.join(out_intergrade_fasthigashi_spot_dir,f'{sample_name}@@{spot}.contact.tsv.gz')\n",
    "                # subprocess.run(f'ln -s {spot_f_path} {out_spot_lnk_path} -f',shell=True)\n",
    "                f.write(f'{out_spot_lnk_path}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spot_id</th>\n",
       "      <th>sample</th>\n",
       "      <th>spot_raw_read_num</th>\n",
       "      <th>spot_raw_C_num</th>\n",
       "      <th>spot_raw_ct_num</th>\n",
       "      <th>spot_fcsize_read_num</th>\n",
       "      <th>spot_fcsize_C_num</th>\n",
       "      <th>spot_fcsize_ct_num</th>\n",
       "      <th>spot_fcsize_cis_ct_num</th>\n",
       "      <th>spot_fcsize_cis_ct_num_ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>fasthigashi_kmeans_10</th>\n",
       "      <th>fasthigashi_kmeans_11</th>\n",
       "      <th>fasthigashi_kmeans_12</th>\n",
       "      <th>fasthigashi_kmeans_13</th>\n",
       "      <th>fasthigashi_kmeans_14</th>\n",
       "      <th>fasthigashi_kmeans</th>\n",
       "      <th>leiden_res_1.00</th>\n",
       "      <th>fasthigashi_leiden</th>\n",
       "      <th>fasthigashi_leiden_anno</th>\n",
       "      <th>fasthigashi_leiden_anno_man</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oddBo81.evenBo61</td>\n",
       "      <td>E11.5L1</td>\n",
       "      <td>14962</td>\n",
       "      <td>5303</td>\n",
       "      <td>362025</td>\n",
       "      <td>11101</td>\n",
       "      <td>1442</td>\n",
       "      <td>362025</td>\n",
       "      <td>75446</td>\n",
       "      <td>0.208400</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oddBo36.evenBo34</td>\n",
       "      <td>E11.5L1</td>\n",
       "      <td>31340</td>\n",
       "      <td>3912</td>\n",
       "      <td>12754783</td>\n",
       "      <td>18944</td>\n",
       "      <td>1053</td>\n",
       "      <td>2504051</td>\n",
       "      <td>363528</td>\n",
       "      <td>0.145176</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Liver</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oddBo41.evenBo54</td>\n",
       "      <td>E11.5L1</td>\n",
       "      <td>13177</td>\n",
       "      <td>4897</td>\n",
       "      <td>694965</td>\n",
       "      <td>9278</td>\n",
       "      <td>998</td>\n",
       "      <td>694965</td>\n",
       "      <td>116855</td>\n",
       "      <td>0.168145</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Liver</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oddBo24.evenBo53</td>\n",
       "      <td>E11.5L1</td>\n",
       "      <td>18320</td>\n",
       "      <td>2051</td>\n",
       "      <td>3261907</td>\n",
       "      <td>14842</td>\n",
       "      <td>664</td>\n",
       "      <td>2167785</td>\n",
       "      <td>275702</td>\n",
       "      <td>0.127181</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Brain</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oddBo20.evenBo85</td>\n",
       "      <td>E11.5L1</td>\n",
       "      <td>18307</td>\n",
       "      <td>4150</td>\n",
       "      <td>2318148</td>\n",
       "      <td>13778</td>\n",
       "      <td>941</td>\n",
       "      <td>1446288</td>\n",
       "      <td>162796</td>\n",
       "      <td>0.112561</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Brain</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            spot_id   sample  spot_raw_read_num  spot_raw_C_num  \\\n",
       "0  oddBo81.evenBo61  E11.5L1              14962            5303   \n",
       "1  oddBo36.evenBo34  E11.5L1              31340            3912   \n",
       "2  oddBo41.evenBo54  E11.5L1              13177            4897   \n",
       "3  oddBo24.evenBo53  E11.5L1              18320            2051   \n",
       "4  oddBo20.evenBo85  E11.5L1              18307            4150   \n",
       "\n",
       "   spot_raw_ct_num  spot_fcsize_read_num  spot_fcsize_C_num  \\\n",
       "0           362025                 11101               1442   \n",
       "1         12754783                 18944               1053   \n",
       "2           694965                  9278                998   \n",
       "3          3261907                 14842                664   \n",
       "4          2318148                 13778                941   \n",
       "\n",
       "   spot_fcsize_ct_num  spot_fcsize_cis_ct_num  spot_fcsize_cis_ct_num_ratio  \\\n",
       "0              362025                   75446                      0.208400   \n",
       "1             2504051                  363528                      0.145176   \n",
       "2              694965                  116855                      0.168145   \n",
       "3             2167785                  275702                      0.127181   \n",
       "4             1446288                  162796                      0.112561   \n",
       "\n",
       "   ...  fasthigashi_kmeans_10  fasthigashi_kmeans_11  fasthigashi_kmeans_12  \\\n",
       "0  ...                      7                      6                      6   \n",
       "1  ...                      3                      3                      7   \n",
       "2  ...                      5                      4                     11   \n",
       "3  ...                      8                      2                      8   \n",
       "4  ...                      1                      5                      0   \n",
       "\n",
       "   fasthigashi_kmeans_13  fasthigashi_kmeans_14  fasthigashi_kmeans  \\\n",
       "0                      7                      5                   2   \n",
       "1                      8                     12                   0   \n",
       "2                     10                      3                   0   \n",
       "3                      5                     13                   5   \n",
       "4                     12                      2                   5   \n",
       "\n",
       "   leiden_res_1.00  fasthigashi_leiden  fasthigashi_leiden_anno  \\\n",
       "0                1                   0                     None   \n",
       "1                3                   2                    Liver   \n",
       "2                3                   2                    Liver   \n",
       "3                0                   1                    Brain   \n",
       "4                0                   1                    Brain   \n",
       "\n",
       "   fasthigashi_leiden_anno_man  \n",
       "0                         None  \n",
       "1                         None  \n",
       "2                         None  \n",
       "3                         None  \n",
       "4                         None  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spot_infor_all=pd.DataFrame()\n",
    "\n",
    "for sample_name in kept_samples:\n",
    "    spot_infor_f=os.path.join(work_dir,'higashi_v2','fasthigashi',sample_name+'_fasthigashi_obs_new.csv')\n",
    "    spot_infor_tmp=pd.read_csv(spot_infor_f,index_col=0)\n",
    "    spot_infor_all=pd.concat([spot_infor_all,spot_infor_tmp])\n",
    "    del spot_infor_tmp\n",
    "spot_infor_all.to_csv(os.path.join(work_dir,'higashi_v2','fasthigashi','fasthigashi_obs_new_keptsamples_v2.csv'),index=False)\n",
    "spot_infor_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_info_new=spot_infor_all[['fasthigashi_leiden_anno_man','fasthigashi_leiden_anno','sample']].to_dict(orient='list')\n",
    "\n",
    "label_info_f=os.path.join(out_dir,'label_info.pickle')\n",
    "with open (label_info_f,'wb') as f:\n",
    "    pickle.dump(label_info_new, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Prepare the fasthigashi input of config_fasthigashi\n",
    "config_fasthigashi = os.path.join(out_dir,'config_fasthigashi_v1.JSON')\n",
    "template_config =os.path.join(work_dir,\"higashi_v2/fasthigashi\",'config_higashi_template_v1.JSON')\n",
    "with open(template_config, 'r') as f:\n",
    "    config_template = json.load(f)\n",
    "    config_template['config_name']='intergrade'\n",
    "    config_template['data_dir']=out_dir\n",
    "    config_template['temp_dir']=os.path.join(out_dir,'temp_fasthigashi')\n",
    "    config_template['input_format']=\"higashi_v2\"\n",
    "    config_template['header_included']=False\n",
    "    config_template['cpu_num']=cpu_num\n",
    "    config_template['gpu_num']=0\n",
    "    config_template['contact_header']=[\"chrom1\", \"pos1\", \"chrom2\", \"pos2\", \"count\"]\n",
    "    config_template['neighbor_num']=5\n",
    "    config_template['UMAP_params']['n_neighbors']=umap_n_neighbors\n",
    "    config_template['optional_smooth']=False\n",
    "    config_template['plot_label']='fasthigashi_leiden_anno_man'\n",
    "    config_template['chrom_list']=[x for x in chroms if x not in ['chrM','chrX','chrY']]\n",
    "    config_template['genome_reference_path']=\"/home/mm10.mainchr.sizes\"\n",
    "    config_template['cytoband_path']=\"/home/spaceA/higashi_v2/fasthigashi/mm10_cytoBand.txt\"\n",
    "\n",
    "with open(config_fasthigashi, 'w') as file:\n",
    "        json.dump(config_template, file, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run the Fast-Higashi model on its own or as an initialization for Higashi\n",
    "### 3.1 Initialize Fast-Higashi model and turn sparse matrices into sparse tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting to gpu:0 available memory = 5111 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fh_model = FastHigashi(config_path=config_fasthigashi,\n",
    "                    path2input_cache=None, # when setting at None, will use the temp_dir on the JSON file\n",
    "                    path2result_dir=None, # same as above\n",
    "                    off_diag=100,\n",
    "                    filter=filter_spot,\n",
    "                    do_conv=do_conv, # at coarser resolution for high cov data, recommend to be False\n",
    "                    do_rwr=do_rwr, # For high-cov data, the differences are minor, will show later with do_rwr=True option\n",
    "                    do_col=False,\n",
    "                    no_col=False)\n",
    "\n",
    "\n",
    "# config_path           The path to the configuration JSON file that you created.\n",
    "# path2input_cache      The path to the directory where the cached tensor file will be stored\n",
    "# path2result_dir       The path to the directory where the cached tensor file will be stored\n",
    "# off_diag              Maximum No of diagonals to consider. When set as 100, the 0-100th diagonal would \n",
    "#                       be considered\n",
    "# filter                Whether only use cells that pass the quality control standard to learn the meta-interactions, \n",
    "#                       and then infers the embeddings for the result of the cells. \n",
    "# do_conv               Whether use linear convolution or not.\n",
    "# do_rwr                Whether use partial random walk with restart or not\n",
    "# do_col                Whether use sqrt_vc normalization or not, the program \n",
    "#                       would automatically uses it when needed\n",
    "# no_col                Whether force the program to not use sqrt_vc normalization, the program would automatically uses it when needed\n",
    "# batch_norm            Whether uses batch corrected normalization or not\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating start/end dict for chromosome\n",
      "extracting from filelist.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2435370f20204f0ca308e58effebf476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40564 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fast process finishes\n",
      "contact pairs to sparse mtx takes: 427.31 s\n"
     ]
    }
   ],
   "source": [
    "# From contact pairs to the sparse matrices and store them on disk\n",
    "if not os.path.exists(os.path.join(fh_model.temp_dir, \"raw\", \"%s_sparse_adj.npy\" % fh_model.chrom_list[0])):\n",
    "    start = time.time()\n",
    "    fh_model.fast_process_data()\n",
    "    print(\"contact pairs to sparse mtx takes: %.2f s\" % (time.time() - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of cells that pass qc check 23291 bad 17273 total: 40564\n",
      "cache file = /home/goubo/CRICK/CRICK/spaceA/higashi_v2/fasthigashi/intergrade_v2/temp_fasthigashi/cache_intra_500000_offdiag_100_.pkl\n",
      "saving cached input to /home/goubo/CRICK/CRICK/spaceA/higashi_v2/fasthigashi/intergrade_v2/temp_fasthigashi/cache_intra_500000_offdiag_100_.pkl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "743245d83c0142d786274b869b261930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sparse mtx into tensors:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "337abb4cae064677b935c1138d71c447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "breaking into batches:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity 0.17845394468090295\n",
      "do_conv True do_rwr False do_col False\n",
      "recommend_bs_cell [3688, 4057, 4508, 4508, 5071, 5071, 5071, 2536, 2705, 2536, 2705, 2705, 2705, 2705, 3381, 3688, 3688, 4057, 6761] pinning memory\n",
      "packing sparse mtx takes: 1233.48 s\n"
     ]
    }
   ],
   "source": [
    "# packing data from sparse matrices to sparse tensors\n",
    "start = time.time()\n",
    "fh_model.prep_dataset(batch_norm=batch_norm) # we don't have batch_id provided so, set as False\n",
    "print(\"packing sparse mtx takes: %.2f s\" % (time.time() - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim1_0.6_rank_256_niterp_1_\n",
      "n_iter_parafac 1\n",
      "empty params initialized\n",
      "time elapsed: 0.53\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "585b5f0a3ddd43fabbafa070db0a94b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "initializing params:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rwr iters: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "time elapsed: 93.53\n",
      "finish init\n",
      "Starting iteration 0\n",
      "\n",
      "PARAFAC2 re=3.156 takes 50.0s\n",
      "Starting iteration 1\n",
      "\n",
      "PARAFAC2 re=0.830 9.31e-01 variation min8.8e-01 at chrom 18, max9.5e-01 at chrom 0 takes 44.3s\n",
      "Starting iteration 2\n",
      "\n",
      "PARAFAC2 re=0.796 8.16e-02 variation min4.0e-02 at chrom 0, max1.0e-01 at chrom 16 takes 44.7s\n",
      "Starting iteration 3\n",
      "\n",
      "PARAFAC2 re=0.780 3.94e-02 variation min2.6e-02 at chrom 0, max1.0e-01 at chrom 18 takes 44.8s\n",
      "Starting iteration 4\n",
      "\n",
      "PARAFAC2 re=0.777 7.56e-03 variation min4.0e-03 at chrom 0, max5.8e-02 at chrom 18 takes 44.9s\n",
      "Starting iteration 5\n",
      "\n",
      "PARAFAC2 re=0.776 2.28e-03 variation min7.2e-04 at chrom 0, max2.2e-02 at chrom 18 takes 44.9s\n",
      "Starting iteration 6\n",
      "\n",
      "PARAFAC2 re=0.776 1.05e-03 variation min8.7e-05 at chrom 1, max8.8e-03 at chrom 18 takes 44.9s\n",
      "Starting iteration 7\n",
      "\n",
      "PARAFAC2 re=0.775 6.19e-04 variation min-5.2e-05 at chrom 1, max4.9e-03 at chrom 18 takes 44.9s\n",
      "Starting iteration 8\n",
      "\n",
      "PARAFAC2 re=0.775 4.21e-04 variation min-1.2e-04 at chrom 1, max3.6e-03 at chrom 18 takes 44.9s\n",
      "Starting iteration 9\n",
      "\n",
      "PARAFAC2 re=0.775 3.13e-04 variation min-1.4e-04 at chrom 1, max3.1e-03 at chrom 18 takes 44.8s\n",
      "Starting iteration 10\n",
      "\n",
      "PARAFAC2 re=0.775 2.45e-04 variation min-1.5e-04 at chrom 1, max2.8e-03 at chrom 18 takes 45.0s\n",
      "converged in 10 iterations.\n",
      "start transform\n",
      "takes: 605.64 s\n"
     ]
    }
   ],
   "source": [
    "fh_model.run_model(extra=\"\", # can be any words, this will be appended to the model name when the model is saved. Used as an identifier.\n",
    "                rank=256,\n",
    "                n_iter_parafac=1,\n",
    "                tol=tolerance #3e-4 # In the original manuscript, we use this tolerance, but later we found that setting it to smaller ones might lead to better performance on some data. Will do an ablation later\n",
    "                )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "# loading existing trained models\n",
    "# This operation is optional when the model is just trained\n",
    "fh_model.load_model(extra=\"\",rank=256,n_iter_parafac=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching embedding\n"
     ]
    }
   ],
   "source": [
    "# getting embedding\n",
    "embed = fh_model.fetch_cell_embedding(final_dim=256,\n",
    "                                    restore_order=restore_order)\n",
    "# The returned embed is a dictionary that stores the embeddings after different ways of post-processing.\n",
    "# 'embed_l2_norm' or 'embed_l2_norm_correct_coverage_fh' usually yields the best results, the latter one represents linear correction of sequencing depth bias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh_model.correct_batch_linear(\"sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['embed_all', 'embed_raw', 'embed_l2_norm', 'restore_order', 'embed_correct_coverage_fh', 'embed_l2_norm_correct_coverage_fh', 'embed_correct_sample', 'embed_l2_norm_correct_sample'])\n"
     ]
    }
   ],
   "source": [
    "print(embed.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save embedding\n",
    "embed_f='embed.pickle'\n",
    "if not os.path.exists(embed_f):\n",
    "    with open (embed_f,'wb') as f:\n",
    "        pickle.dump(embed, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
